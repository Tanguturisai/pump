{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77430a15",
   "metadata": {},
   "source": [
    "# Predictive Maintenance for HVAC Pumps\n",
    "This notebook demonstrates predictive maintenance using sensor data from HVAC pumps.\n",
    "We will explore the data, perform preprocessing, engineer features, train models, compare results, and deploy the best model using FastAPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2962fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"sensor.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e3768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 10% missing values\n",
    "threshold = len(df) * 0.9\n",
    "df.dropna(axis=1, thresh=threshold, inplace=True)\n",
    "\n",
    "# Drop columns with all nulls\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Fill remaining missing values\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccccc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Encode target variable\n",
    "df['machine_status'] = df['machine_status'].map({'NORMAL': 0, 'RECOVERING': 1, 'BROKEN': 2})\n",
    "df['machine_status'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b891fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df.drop(columns=['Unnamed: 0', 'timestamp', 'machine_status'], errors='ignore')\n",
    "y = df['machine_status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c7d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and comparison\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(probability=True)\n",
    "}\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[name] = report['weighted avg']['f1-score']\n",
    "    print(f\"\\n{name} Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "best_model_name = max(results, key=results.get)\n",
    "print(f\"\\nBest Model: {best_model_name}, F1 Score: {results[best_model_name]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e441e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model and scaler\n",
    "best_model = models[best_model_name]\n",
    "joblib.dump(best_model, \"best_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e324ed",
   "metadata": {},
   "source": [
    "## Deployment Instructions\n",
    "Use the following Python script (`fastapi_app.py`) to deploy your model:\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class SensorData(BaseModel):\n",
    "    values: list\n",
    "\n",
    "@app.post('/predict')\n",
    "def predict(data: SensorData):\n",
    "    model = joblib.load('best_model.pkl')\n",
    "    scaler = joblib.load('scaler.pkl')\n",
    "    arr = np.array(data.values).reshape(1, -1)\n",
    "    arr_scaled = scaler.transform(arr)\n",
    "    pred = model.predict(arr_scaled)\n",
    "    return {'prediction': int(pred[0])}\n",
    "```\n",
    "\n",
    "Run the API with:\n",
    "`uvicorn fastapi_app:app --reload`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
